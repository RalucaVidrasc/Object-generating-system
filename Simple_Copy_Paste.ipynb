{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isq7wp1QsWED",
        "outputId": "419cfebf-cf38-4c06-ec0b-aa6a36b4788b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhLwQbOxitSE"
      },
      "outputs": [],
      "source": [
        "!unzip -qq /content/drive/MyDrive/datasets/coco/annotations_trainval2017.zip -d /content\n",
        "!unzip -qq /content/drive/MyDrive/datasets/coco/train2017.zip -d /content\n",
        "!unzip -qq /content/drive/MyDrive/datasets/coco/val2017.zip -d /content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCbeJH7s7qO5"
      },
      "source": [
        "# Auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRzd5hxvEq9C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "def mask_to_segmentation(mask):\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    segmentation = []\n",
        "    # each coutour has the shape: (n, 1, 2)  ; n = nr of points; 1 - redundant dimension; 2 - the (x, y) coordinates\n",
        "    for contour in contours:\n",
        "        contour = np.squeeze(contour, axis = 1)\n",
        "        for point in contour:\n",
        "            segmentation.extend([int(point[0]), int(point[1])])\n",
        "\n",
        "    return segmentation\n",
        "\n",
        "def rotate_image(image, angle):\n",
        "    height, width = image.shape[:2]\n",
        "    center = (width / 2, height / 2)\n",
        "\n",
        "    matrix = cv2.getRotationMatrix2D(center, angle, 1)\n",
        "    rotated_img = cv2.warpAffine(image, matrix, (width, height))\n",
        "\n",
        "    return rotated_img\n",
        "\n",
        "\n",
        "def resize_instance_and_mask(instance, mask, scale, dest_shape):\n",
        "    if instance is None:\n",
        "        return instance, mask, [0, 0, 0, 0]\n",
        "\n",
        "    original_h, original_w = instance.shape[:2]\n",
        "    new_h, new_w = int(scale * original_h), int(scale * original_w)\n",
        "\n",
        "    # dimensions need to be at least 1 pixel\n",
        "    new_h = max(1, new_h)\n",
        "    new_w = max(1, new_w)\n",
        "\n",
        "    # randomly rotate the instance and its mask for 50% cases\n",
        "    if random.random() < 0.5:\n",
        "        angle = random.randint(0, 360)\n",
        "        instance = rotate_image(instance, angle)\n",
        "        mask = rotate_image(mask, angle)\n",
        "\n",
        "    resized_instance = cv2.resize(instance, (new_w, new_h))\n",
        "    resized_mask = cv2.resize(mask, (new_w, new_h))\n",
        "\n",
        "    # randomly flip horizontally in 70% cases\n",
        "    if random.random() < 0.7:\n",
        "        resized_instance = cv2.flip(resized_instance, 1)\n",
        "        resized_mask = cv2.flip(resized_mask, 1)\n",
        "\n",
        "    # double the size if it's smaller than 70x70 pixels\n",
        "    if new_h * new_w < 4900:\n",
        "        new_h *= 2\n",
        "        new_w *= 2\n",
        "        resized_instance = cv2.resize(resized_instance, (new_w, new_h))\n",
        "        resized_mask = cv2.resize(resized_mask, (new_w, new_h))\n",
        "\n",
        "    if new_h > dest_shape[0] or new_w > dest_shape[1]:\n",
        "        y_offset = random.randint(0, max(0, new_h - dest_shape[0]))\n",
        "        x_offset = random.randint(0, max(0, new_w - dest_shape[1]))\n",
        "        resized_instance = resized_instance[y_offset : y_offset + dest_shape[0], x_offset : x_offset + dest_shape[1]]\n",
        "        resized_mask = resized_mask[y_offset : y_offset + dest_shape[0], x_offset : x_offset + dest_shape[1]]\n",
        "\n",
        "    contours, _ = cv2.findContours(resized_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours) > 0:\n",
        "        bbox = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
        "    else:\n",
        "        bbox = (0, 0, 0, 0)\n",
        "\n",
        "    area_of_bbox = bbox[2] * bbox[3]\n",
        "    total_area = dest_shape[0] * dest_shape[1]\n",
        "\n",
        "    # if the bbox of the instance occupies more than 60% of the total area, adjust it\n",
        "    if area_of_bbox / total_area > 0.6:\n",
        "        new_h = int(resized_instance.shape[0] * (2/3))\n",
        "        new_w = int(resized_instance.shape[1] * (2/3))\n",
        "        resized_instance = cv2.resize(resized_instance, (new_w, new_h))\n",
        "        resized_mask = cv2.resize(resized_mask, (new_w, new_h))\n",
        "\n",
        "        contours, _ = cv2.findContours(resized_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if len(contours) > 0:\n",
        "            bbox = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
        "        else:\n",
        "            bbox = (0, 0, 0, 0)\n",
        "\n",
        "    return resized_instance, resized_mask, bbox\n",
        "\n",
        "def generate_unique_ids(coco_dataset, num_ids=1000):\n",
        "    existing_ids = set(coco_dataset.getAnnIds())\n",
        "    all_ids = set(range(1, num_ids + 1))\n",
        "    unique_ids = all_ids - existing_ids\n",
        "    return unique_ids\n",
        "\n",
        "def get_anchor_point(original_dim, new_dim):\n",
        "    position = random.choice(['tl', 'tr', 'bl', 'br', 'center'])  # top-left, top-right, bottom l/r\n",
        "\n",
        "    if position == 'tl':\n",
        "        return 0, 0\n",
        "    elif position == 'tr':\n",
        "        return original_dim[0] - new_dim[0], 0\n",
        "    elif position == 'bl':\n",
        "        return 0, original_dim[1] - new_dim[1]\n",
        "    elif position == 'br':\n",
        "        return original_dim[0] - new_dim[0], original_dim[1] - new_dim[1]\n",
        "    elif position == 'center':\n",
        "        return (original_dim[0] - new_dim[0]) // 2, (original_dim[1] - new_dim[1]) // 2\n",
        "\n",
        "def adjust_annotations(coco, annotations, scale, new_w, new_h, original_w, original_h, ann_ids, anchor_x=0, anchor_y=0):\n",
        "    new_annotations = []\n",
        "\n",
        "    for ann in annotations:\n",
        "        new_ann = ann.copy()\n",
        "\n",
        "        if 'bbox' in ann:\n",
        "            x, y, w, h = ann['bbox']\n",
        "            new_x = (x * scale) + anchor_x\n",
        "            new_y = (y * scale) + anchor_y\n",
        "            new_w = w * scale\n",
        "            new_h = h * scale\n",
        "\n",
        "            new_ann['bbox'] = [new_x, new_y, new_w, new_h]\n",
        "\n",
        "        if 'segmentation' in ann:\n",
        "            new_segmentations = []\n",
        "            for seg in ann['segmentation']:\n",
        "                new_seg = []\n",
        "                if isinstance(seg, list):\n",
        "                    for i in range(0, len(seg), 2):\n",
        "                        x, y = seg[i], seg[i+1]\n",
        "                        new_x = (x * scale) + anchor_x\n",
        "                        new_y = (y * scale) + anchor_y\n",
        "                        new_seg.extend([new_x, new_y])\n",
        "                else:\n",
        "                    new_seg = seg\n",
        "                new_segmentations.append(new_seg)\n",
        "            new_ann['segmentation'] = new_segmentations\n",
        "\n",
        "            new_ann['id'] = ann_ids.pop()\n",
        "\n",
        "        new_annotations.append(new_ann)\n",
        "\n",
        "    return new_annotations, ann_ids\n",
        "\n",
        "def resize_image_and_annotations(coco, image, scale, annotations=[], ann_ids=[]):\n",
        "    original_h, original_w = image.shape[:2]\n",
        "    new_h, new_w = int(scale * original_h), int(scale * original_w)\n",
        "\n",
        "    resized_img = cv2.resize(image, (new_w, new_h))\n",
        "\n",
        "    anchor_x, anchor_y = 0, 0\n",
        "\n",
        "    if scale < 1:\n",
        "        final_img = np.ones((original_h, original_w, 3), dtype = np.uint8) * 127\n",
        "        anchor_x, anchor_y = get_anchor_point((original_w, original_h), (new_w, new_h))\n",
        "        final_img[anchor_y : anchor_y + new_h, anchor_x : anchor_x + new_w] = resized_img\n",
        "\n",
        "    else:\n",
        "        y_offset = 0\n",
        "        x_offset = 0\n",
        "        if new_h - original_h > 0:\n",
        "            y_offset = random.randint(0, int(new_h - original_h))\n",
        "        if new_w - original_w > 0:\n",
        "            x_offset = random.randint(0, int(new_w - original_w))\n",
        "        final_img = resized_img[y_offset : y_offset + original_h, x_offset : x_offset + original_w]\n",
        "\n",
        "    adjusted_annotations, remaining_ids = adjust_annotations(coco, annotations, scale, new_w, new_h, original_w, original_h, ann_ids, anchor_x, anchor_y)\n",
        "\n",
        "    return final_img, adjusted_annotations, remaining_ids\n",
        "\n",
        "\n",
        "def add_offset_to_annotations(segmentation, bbox, offset):\n",
        "  x_offset, y_offset = offset\n",
        "  x, y, _, _ = bbox\n",
        "  x += x_offset\n",
        "  y += y_offset\n",
        "\n",
        "  new_bbox = (x, y, bbox[2], bbox[3])\n",
        "\n",
        "  for i in range(0, len(segmentation), 2):\n",
        "    segmentation[i] += x_offset\n",
        "    segmentation[i+1] += y_offset\n",
        "\n",
        "  return new_bbox, segmentation\n",
        "\n",
        "def check_overlap(bbox1, bbox2):\n",
        "    x1_a, y1_a, x2_a, y2_a = bbox1\n",
        "    x1_b, y1_b, x2_b, y2_b = bbox2\n",
        "    return x1_a < x2_b and x1_b < x2_a and y1_a < y2_b and y1_b < y2_a\n",
        "\n",
        "def do_bboxes_intersect(bbox1, bbox2):\n",
        "    return not (bbox1[0] + bbox1[2] <= bbox2[0] or  # bbox1 left bbox2 right\n",
        "                bbox1[0] >= bbox2[0] + bbox2[2] or  # bbox1 right bbox2 left\n",
        "                bbox1[1] + bbox1[3] <= bbox2[1] or  # bbox1 top bbox2 bottom\n",
        "                bbox1[1] >= bbox2[1] + bbox2[3])    # bbox1 bottom bbox2 top"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB7TP1-h7AKp"
      },
      "source": [
        "# Split the annotations into subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9roBf_MK_o7z",
        "outputId": "c995698a-7aaa-4a0a-c9e1-b9bf9aca11da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=14.96s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "from pycocotools.coco import COCO\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "\n",
        "annotation_file = '/content/annotations/instances_train2017.json'\n",
        "\n",
        "\n",
        "output_directory = '/content/sample_data/split_annon'\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "coco = COCO(annotation_file)\n",
        "\n",
        "image_ids = list(coco.imgs.keys())\n",
        "\n",
        "num_subsets = 20\n",
        "images_per_subset = math.ceil(len(image_ids) / num_subsets)\n",
        "\n",
        "\n",
        "for subset_idx in range(num_subsets):\n",
        "    start_idx = subset_idx * images_per_subset\n",
        "    end_idx = min(start_idx + images_per_subset, len(image_ids))\n",
        "    subset_image_ids = image_ids[start_idx:end_idx]\n",
        "\n",
        "    subset_annotations = coco.loadAnns(coco.getAnnIds(imgIds=subset_image_ids))\n",
        "    subset_images = coco.loadImgs(subset_image_ids)\n",
        "\n",
        "    subset_data = {\n",
        "        'info': coco.dataset['info'],\n",
        "        'licenses': coco.dataset['licenses'],\n",
        "        'categories': coco.dataset['categories'],\n",
        "        'images': subset_images,\n",
        "        'annotations': subset_annotations\n",
        "    }\n",
        "\n",
        "    output_filename = os.path.join(output_directory, f'subset_{subset_idx}.json')\n",
        "    if os.path.exists(output_filename):\n",
        "        os.remove(output_filename)\n",
        "\n",
        "    with open(output_filename, 'w') as f:\n",
        "        json.dump(subset_data, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj6a80kn7t7k"
      },
      "source": [
        "# The image processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9VoNhOr1a-P"
      },
      "outputs": [],
      "source": [
        "def process_image_func(args):\n",
        "    img_id, coco, cat_ids, instances_to_copy, added_instances, images, ann_ids, counter, proccessing_type = args\n",
        "\n",
        "    counter.value += 1\n",
        "    if counter.value % 250 == 0:\n",
        "      print(counter.value)\n",
        "\n",
        "    cat_img_ids = coco.getImgIds(catIds=cat_ids)\n",
        "    dest_img_info = coco.loadImgs([img_id])[0]\n",
        "    dest_img_ann_id = coco.getAnnIds(imgIds=dest_img_info['id'])\n",
        "    dest_img_ann = coco.loadAnns(dest_img_ann_id)\n",
        "\n",
        "\n",
        "    # delete the old  anns for the current image\n",
        "    old_ann_ids = [ann['id'] for ann in coco.dataset['annotations'] if ann['image_id'] == dest_img_info['id']]\n",
        "\n",
        "    dest_img = cv2.imread(os.path.join(images, dest_img_info['file_name']))\n",
        "    if dest_img is None:\n",
        "        print(\"Somthing is None\")\n",
        "        return 0, [], None, dest_img_info['file_name'], []\n",
        "\n",
        "    scale_dest = random.uniform(0.5, 1)\n",
        "    final_dest_img, new_ann, remaining_ann_ids = resize_image_and_annotations(coco, dest_img, scale_dest, dest_img_ann, ann_ids)\n",
        "\n",
        "    instances_no = 0\n",
        "    for ann in new_ann:\n",
        "      if ann['category_id'] == cat_ids[0]:\n",
        "        instances_no += 1\n",
        "        break\n",
        "\n",
        "    # 1 - images with people\n",
        "    # 2 - images without people\n",
        "    # 3 - all imges\n",
        "\n",
        "    if proccessing_type == 1 and instances_no == 0:\n",
        "        return 0, new_ann, final_dest_img, dest_img_info['file_name'], old_ann_ids\n",
        "\n",
        "    elif proccessing_type == 2 and instances_no == 1:\n",
        "        return 0, new_ann, final_dest_img, dest_img_info['file_name'], old_ann_ids\n",
        "\n",
        "\n",
        "    if added_instances < instances_to_copy:\n",
        "        ann_ids = coco.getAnnIds(imgIds = img_id)\n",
        "        if ann_ids:\n",
        "            source_img_id = img_id\n",
        "            while source_img_id == img_id:\n",
        "                source_img_id = random.choice(cat_img_ids)\n",
        "\n",
        "            source_ann_ids = coco.getAnnIds(imgIds = source_img_id, catIds = cat_ids)\n",
        "            source_anns = coco.loadAnns(source_ann_ids)\n",
        "            num_instances_to_copy_from_this_image = random.randint(1, len(source_anns))\n",
        "\n",
        "            for _ in range(num_instances_to_copy_from_this_image):\n",
        "                if added_instances >= instances_to_copy:\n",
        "                    break\n",
        "\n",
        "                ann = random.choice(source_anns)\n",
        "                source_anns.remove(ann)\n",
        "                source_img = cv2.imread(os.path.join(images, coco.loadImgs([source_img_id])[0]['file_name']))\n",
        "\n",
        "                if source_img is None:\n",
        "                    num_instances_to_copy_from_this_image -= 1\n",
        "                    continue\n",
        "\n",
        "                mask = coco.annToMask(ann)\n",
        "                x, y, w, h = [int(i) for i in ann['bbox']]\n",
        "                mask = (mask > 0).astype(np.uint8) * 255\n",
        "                person = source_img[y : y + h, x : x + w]\n",
        "                person_mask =  mask[y : y + h, x : x + w]\n",
        "\n",
        "                # for better image variety -- scale jittering\n",
        "                scale_instance = random.uniform(0.7, 1.5)\n",
        "                resized_person, resized_mask, resized_bbox = resize_instance_and_mask(person, person_mask, scale_instance, final_dest_img.shape)\n",
        "\n",
        "                all_bboxes = [ann_element['bbox'] for ann_element in new_ann]\n",
        "                y1 = random.randint(0, final_dest_img.shape[0] - resized_mask.shape[0])\n",
        "                x1 = random.randint(0, final_dest_img.shape[1] - resized_mask.shape[1])\n",
        "                segmentation = mask_to_segmentation(resized_mask)\n",
        "                added_bbox, added_seg = add_offset_to_annotations(segmentation, resized_bbox, (x1, y1))\n",
        "                attempts = 10\n",
        "                while any(do_bboxes_intersect(added_bbox, bbox) for bbox in all_bboxes) and attempts > 0:\n",
        "                    y1 = random.randint(0, final_dest_img.shape[0] - resized_mask.shape[0])\n",
        "                    x1 = random.randint(0, final_dest_img.shape[1] - resized_mask.shape[1])\n",
        "                    segmentation = mask_to_segmentation(resized_mask)\n",
        "                    added_bbox, added_seg = add_offset_to_annotations(segmentation, resized_bbox, (x1, y1))\n",
        "                    attempts -= 1\n",
        "\n",
        "                roi = final_dest_img[y1 : y1 + resized_mask.shape[0], x1 : x1 + resized_mask.shape[1]]\n",
        "                for c in range(0, 3):\n",
        "                    roi[:, :, c] = roi[:, :, c] * (1 - (resized_mask / 255.0)) + resized_person[:, :, c] * (resized_mask / 255.0)\n",
        "\n",
        "                added_instances += 1\n",
        "                new_annotation = {\n",
        "                  'image_id': dest_img_info['id'],\n",
        "                  'category_id': cat_ids[0],\n",
        "                  'bbox': added_bbox,\n",
        "                  'segmentation': [added_seg],\n",
        "                  'iscrowd': 0,\n",
        "                  'id': remaining_ann_ids.pop()\n",
        "                }\n",
        "                new_ann.append(new_annotation)\n",
        "\n",
        "    return added_instances, new_ann, final_dest_img, dest_img_info['file_name'], old_ann_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57pNFaKX74pO"
      },
      "source": [
        "# Start the processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmDRaIkcrgSE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import json as jsonn\n",
        "from pycocotools.coco import COCO\n",
        "from multiprocessing import Pool\n",
        "from multiprocessing import Manager\n",
        "\n",
        "# create a distribution of the new instances depending on image type\n",
        "def create_distribution(number_of_instances, coco, category_id, type):\n",
        "    total_photos = len(coco.getImgIds())\n",
        "    distrib = [0] * total_photos\n",
        "\n",
        "    all_img_ids = coco.getImgIds()\n",
        "\n",
        "    if type == 1: # images with the specified category\n",
        "        img_ids_with_category = coco.getImgIds(catIds=[category_id])\n",
        "        num_photos_with_category = len(img_ids_with_category)\n",
        "        rest = number_of_instances % num_photos_with_category\n",
        "        value = int(number_of_instances / num_photos_with_category)\n",
        "\n",
        "        for img_id in img_ids_with_category:\n",
        "            index = all_img_ids.index(img_id)\n",
        "            distrib[index] = value\n",
        "        for i in range(rest):\n",
        "            index = all_img_ids.index(img_ids_with_category[i])\n",
        "            distrib[index] += 1\n",
        "\n",
        "    elif type == 2: #images without the specified category\n",
        "        img_ids_without_category = set(all_img_ids) - set(coco.getImgIds(catIds=[category_id]))\n",
        "        num_photos_without_category = len(img_ids_without_category)\n",
        "        rest = number_of_instances % num_photos_without_category\n",
        "        value = int(number_of_instances / num_photos_without_category)\n",
        "\n",
        "        for img_id in img_ids_without_category:\n",
        "            index = all_img_ids.index(img_id)\n",
        "            distrib[index] = value\n",
        "        for i, img_id in enumerate(img_ids_without_category):\n",
        "            if i < rest:\n",
        "                index = all_img_ids.index(img_id)\n",
        "                distrib[index] += 1\n",
        "\n",
        "    elif type == 3:  # all images\n",
        "        rest = number_of_instances % total_photos\n",
        "        value = int(number_of_instances / total_photos)\n",
        "        for i in range(total_photos):\n",
        "            distrib[i] = value\n",
        "        for i in range(rest):\n",
        "            distrib[i] += 1\n",
        "\n",
        "    return distrib\n",
        "\n",
        "\n",
        "def create_ann_ids_lists(coco, distrib):\n",
        "  available_ids = generate_unique_ids(coco, 100000000)\n",
        "  ret_list = []\n",
        "  for i, x in enumerate(distrib):\n",
        "    add_list = []\n",
        "    for j in range(x+120):\n",
        "      add_list.append(available_ids.pop())\n",
        "    ret_list.append(add_list)\n",
        "  return ret_list\n",
        "\n",
        "\n",
        "def simple_copy_paste_parallel(cat, percent, images, json, output_folder, proc_type):\n",
        "    coco = COCO(json)\n",
        "    cat_ids = [cat]\n",
        "    cat_img_ids = coco.getImgIds(catIds=cat_ids)\n",
        "\n",
        "    coco.dataset['annotations'] = [x for x in coco.dataset['annotations'] if x['category_id'] in cat_ids]\n",
        "    initial_instances = sum([len(coco.getAnnIds(imgIds=img_id, catIds=cat_ids)) for img_id in cat_img_ids])\n",
        "\n",
        "    instances_to_copy = int(initial_instances * (percent / 100))\n",
        "    distribution = create_distribution(instances_to_copy, coco, cat, proc_type)\n",
        "\n",
        "    list_of_ann_ids = create_ann_ids_lists(coco, distribution)\n",
        "\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "    all_img_ids = coco.getImgIds()\n",
        "\n",
        "    total_images = len(all_img_ids)\n",
        "    added_instances = 0\n",
        "    tasks = []\n",
        "    manager = Manager()     # to coordinate and share data between processes\n",
        "    processed_images_counter = manager.Value('i', 0)      # shared counter to keep track of the number of processed images\n",
        "\n",
        "    for idx, img_id in enumerate(all_img_ids):\n",
        "      tasks.append((img_id, coco, cat_ids, distribution[idx], added_instances, images, list_of_ann_ids[idx], processed_images_counter, proc_type))\n",
        "\n",
        "\n",
        "    with Pool(os.cpu_count()) as p:\n",
        "        for index, result in enumerate(p.map(process_image_func, tasks)):\n",
        "            if (index + 1) % 200 == 0:\n",
        "              print(f\"Processed image {index + 1} of {total_images}\")\n",
        "\n",
        "            added_for_this_image, new_ann, final_dest_img, filename, old_ann_ids = result\n",
        "            added_instances += added_for_this_image\n",
        "\n",
        "            if final_dest_img is not None:\n",
        "                cv2.imwrite(os.path.join(output_folder, filename), final_dest_img)\n",
        "\n",
        "            coco.dataset['annotations'].extend(new_ann)\n",
        "            coco.dataset['annotations'] = [ann for ann in coco.dataset['annotations'] if ann['id'] not in old_ann_ids]\n",
        "\n",
        "    coco.dataset['annotations'] = [ann for ann in coco.dataset['annotations'] if ann['category_id'] == cat]\n",
        "\n",
        "    output_json = os.path.join(output_folder, 'annotations.json')\n",
        "    with open(output_json, 'w') as f:\n",
        "        jsonn.dump(coco.dataset, f)\n",
        "\n",
        "    return initial_instances, added_instances, initial_instances + added_instances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjHnJ8Ei3KZ3",
        "outputId": "e552cec3-d06e-4af9-dee8-2f57a57bcf91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'sample_data/images*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r sample_data/images*\n",
        "!rm -r person_train_copy*\n",
        "!rm -r annotations*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uHsgMnsrdUM"
      },
      "outputs": [],
      "source": [
        "for proccessing_type in [2]:\n",
        "  for i in range(2, 20):\n",
        "    print(f\"{'=' * 10} {i} {proccessing_type} {'=' * 10}\")\n",
        "    out = f\"/content/sample_data/images{i}_{proccessing_type}\"\n",
        "    ann = f\"/content/sample_data/split_annon/subset_{i}.json\"\n",
        "    img = \"/content/train2017\"\n",
        "    _, _, _ = simple_copy_paste_parallel(1, 320, img, ann, out, proccessing_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlPvfVN28kka"
      },
      "source": [
        "# Display BBOX and SEGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gY3qM6mg2nJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as pl\n",
        "import numpy as np\n",
        "\n",
        "def load_coco_annotations(annotation_path):\n",
        "    with open(annotation_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "    return coco_data\n",
        "\n",
        "def select_random_images(coco_data, num_images=20):\n",
        "    image_ids = [image['id'] for image in coco_data['images']]\n",
        "    selected_image_ids = random.sample(image_ids, num_images)\n",
        "    return [image for image in coco_data['images'] if image['id'] in selected_image_ids]\n",
        "\n",
        "def select_images_from_directory(coco_data, directory_path):\n",
        "    image_files_in_directory = os.listdir(directory_path)\n",
        "    selected_images = [image for image in coco_data['images'] if image['file_name'] in image_files_in_directory]\n",
        "\n",
        "    return selected_images\n",
        "\n",
        "def get_image_with_bboxes(image_path, annotations, category_names):\n",
        "    image = cv2.imread(image_path)\n",
        "    for ann in annotations:\n",
        "        if 'bbox' in ann:\n",
        "            bbox = ann['bbox']\n",
        "            category_id = ann['category_id']\n",
        "            if category_id == 'person':\n",
        "                category_id = 1\n",
        "            category_name = category_names.get(category_id, \"Unknown\")\n",
        "\n",
        "            x, y, w, h = [int(coord) for coord in bbox]\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(image, category_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        if 'segmentation' in ann and isinstance(ann['segmentation'], list) and len(ann['segmentation']) > 0:\n",
        "            for seg in ann['segmentation']:\n",
        "                if isinstance(seg, list) and len(seg) >= 6:\n",
        "                    np_seg = np.array(seg).reshape((-1, 2)).astype(np.int32)\n",
        "                    cv2.drawContours(image, [np_seg], 0, (0, 0, 255), 2)\n",
        "    return image\n",
        "\n",
        "def main(image_dir, annotation_path):\n",
        "    coco_data = load_coco_annotations(annotation_path)\n",
        "    category_names = {category['id']: category['name'] for category in coco_data['categories']}\n",
        "    selected_images = select_images_from_directory(coco_data, image_dir)\n",
        "\n",
        "    random.shuffle(selected_images)\n",
        "    selected_images = selected_images[:40]\n",
        "\n",
        "    for i, image_info in enumerate(selected_images):\n",
        "        image_path = os.path.join(image_dir, image_info['file_name'])\n",
        "        annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] == image_info['id']]\n",
        "        image_with_bboxes = get_image_with_bboxes(image_path, annotations, category_names)\n",
        "\n",
        "        plt.imshow(cv2.cvtColor(image_with_bboxes, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(\"Image with Bounding Boxes and Segmentation Contours\")\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_directory = \"/content/person_val_copy_paste1\"\n",
        "    annotations_file = \"/content/annotations_1.json\"\n",
        "    main(image_directory, annotations_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQQDrENz8xyu"
      },
      "source": [
        "# Merge all 20 directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1nIP-ZNd7fr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def merge_image_directories(destination_dir):\n",
        "  for proccessing_type in range(2, 3):\n",
        "    dest_dir = f'{destination_dir}{proccessing_type}'\n",
        "    if not os.path.exists(dest_dir):\n",
        "      os.makedirs(dest_dir)\n",
        "\n",
        "    for i in range(20):\n",
        "        source_dir = f\"/content/sample_data/images{i}_{proccessing_type}\"\n",
        "        if os.path.exists(source_dir):\n",
        "            for filename in os.listdir(source_dir):\n",
        "                if filename.endswith(\".jpg\") and filename != \"annotations.jpg\":\n",
        "                    source_filepath = os.path.join(source_dir, filename)\n",
        "                    destination_filepath = os.path.join(dest_dir, filename)\n",
        "\n",
        "                    shutil.copy2(source_filepath, destination_filepath)\n",
        "\n",
        "    print(\"All images were succesfully copied in \", dest_dir)\n",
        "merge_image_directories(\"/content/person_train_copy_paste\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6x2I_vfZWAy"
      },
      "outputs": [],
      "source": [
        "rm -r person_train_copy*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwnM9gVT82wr"
      },
      "source": [
        "# Merge all annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfZqFJ4BfWHc"
      },
      "outputs": [],
      "source": [
        "from pycocotools.coco import COCO\n",
        "import json\n",
        "\n",
        "def merge_coco_annotations(folders):\n",
        "    merged_data = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": []\n",
        "    }\n",
        "\n",
        "    annotation_id = 1\n",
        "\n",
        "    for folder in folders:\n",
        "        annotation_path = f\"{folder}/annotations.json\"\n",
        "        if not os.path.exists(annotation_path):\n",
        "            print(f\"Fișierul {annotation_path} nu există. Se trece la următorul.\")\n",
        "            continue\n",
        "\n",
        "        coco = COCO(annotation_path)\n",
        "        for img in coco.dataset['images']:\n",
        "            merged_data[\"images\"].append(img)\n",
        "\n",
        "        for ann in coco.dataset['annotations']:\n",
        "            ann['id'] = annotation_id\n",
        "            annotation_id += 1\n",
        "            merged_data[\"annotations\"].append(ann)\n",
        "\n",
        "        if not merged_data[\"categories\"]:\n",
        "            merged_data[\"categories\"] = coco.dataset['categories']\n",
        "\n",
        "    return merged_data\n",
        "\n",
        "folders = [[f\"/content/sample_data/images{i}_{j}\" for i in range(20)] for j in range(2, 3)]\n",
        "\n",
        "for i, folders_type in enumerate(folders, start = 2):\n",
        "  merged_data = merge_coco_annotations(folders_type)\n",
        "  with open(f\"/content/annotations_{i}.json\", 'w') as f:\n",
        "      json.dump(merged_data, f)\n",
        "\n",
        "  print(\"Annotations were merged and succesfully merged!\", i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmaHFDSl5yKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd324966-01f6-457c-adf4-f0b01c41f73f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=13.24s)\n",
            "creating index...\n",
            "index created!\n",
            "398050\n"
          ]
        }
      ],
      "source": [
        "\n",
        "c = COCO('annotations_2.json')\n",
        "print(len(c.dataset['annotations']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFwxYlgdNJpk"
      },
      "source": [
        "# ====================== Optional ======================\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xvci--LNVfa",
        "outputId": "d3cb8bbe-5d49-4243-a966-3597fc390224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=13.44s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "coco = COCO(\"annotations_3.json\")\n",
        "\n",
        "max_id = max([img['id'] for img in coco.dataset['images']])\n",
        "\n",
        "for img in coco.dataset['images']:\n",
        "    max_id += 1\n",
        "    old_name = img['file_name']\n",
        "    img['file_name'] = str(max_id).zfill(12) + '.jpg'\n",
        "\n",
        "    old_id = img['id']\n",
        "    ann_ids = coco.getAnnIds([old_id])\n",
        "    anns = coco.loadAnns(ann_ids)\n",
        "    img['id'] = max_id\n",
        "\n",
        "    for ann in anns:\n",
        "        ann['image_id'] = max_id\n",
        "\n",
        "    old_image_path = os.path.join('/content/person_train_copy_paste3', old_name)\n",
        "    new_image_path = os.path.join('/content/person_train_copy_paste3_new', img['file_name'])\n",
        "    shutil.copy2(old_image_path, new_image_path)\n",
        "\n",
        "output_json_path = 'annotations_3_updated.json'\n",
        "with open(output_json_path, 'w') as json_file:\n",
        "    json.dump(coco.dataset, json_file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPEsbk1VdA_p",
        "outputId": "330fa757-50fb-4b6a-e611-bb29db12059b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=16.68s)\n",
            "creating index...\n",
            "index created!\n",
            "327481\n"
          ]
        }
      ],
      "source": [
        "c = COCO(\"/content/annotations_3_updated.json\")\n",
        "print(len(c.dataset['annotations']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge 2 coco datasets if needed"
      ],
      "metadata": {
        "id": "82RCz7Hzghh-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqGsmGo5eSQA",
        "outputId": "a9e33840-05d7-4bfa-ed3d-392d50a0fe94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "581929\n",
            "700216\n",
            "236574\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def merge_coco_datasets(coco1_annotations, coco2_annotations, output_annotations,\n",
        "                        coco1_images_folder, coco2_images_folder, output_images_folder):\n",
        "    with open(coco1_annotations, 'r') as f:\n",
        "        coco1_data = json.load(f)\n",
        "    with open(coco2_annotations, 'r') as f:\n",
        "        coco2_data = json.load(f)\n",
        "\n",
        "\n",
        "\n",
        "    merged_images = coco1_data['images'] + coco2_data['images']\n",
        "    print(max(x['id'] for x in coco1_data['images']))\n",
        "    print(max(x['id'] for x in coco2_data['images']))\n",
        "    print(len(merged_images))\n",
        "    merged_annotations = coco1_data['annotations'] + coco2_data['annotations']\n",
        "    merged_categories = coco1_data['categories']\n",
        "\n",
        "    merged_data = {\n",
        "        'images': merged_images,\n",
        "        'annotations': merged_annotations,\n",
        "        'categories': merged_categories\n",
        "    }\n",
        "\n",
        "    with open(output_annotations, 'w') as f:\n",
        "        json.dump(merged_data, f)\n",
        "\n",
        "merge_coco_datasets(\n",
        "    '/content/annotations/instances_train2017.json',\n",
        "    '/content/annotations_3_updated.json',\n",
        "    '/content/merged_annotations.json',\n",
        "    '/content/train2017',\n",
        "    '/content/person_train_copy_paste3_new',\n",
        "    '/content/merged_images'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-Eup8kSmoa0",
        "outputId": "2f2a5343-918e-4ad3-a353-629ebc48b365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "236574\n",
            "700216\n"
          ]
        }
      ],
      "source": [
        "with open('/content/merged_annotations.json', 'r') as f:\n",
        "  coco1_data = json.load(f)\n",
        "print(len(coco1_data['images']))\n",
        "print(max([x['id'] for x in coco.dataset['images']]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04AMpQYEorSi",
        "outputId": "842368cf-a785-45a2-c19a-75d22f3381a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "589946\n"
          ]
        }
      ],
      "source": [
        "print(len([x for x in coco1_data['annotations'] if x['category_id'] == 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2GN_4S_5TTG"
      },
      "outputs": [],
      "source": [
        "!zip -r  /content/merged_train_with_30_cp.zip /content/merged_images /content/merged_annotations.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XKglYBl_tvz"
      },
      "outputs": [],
      "source": [
        "!mv /content/merged_train_with_30_cp.zip /content/drive/MyDrive/A_new_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3CWdwr6NQ7o"
      },
      "source": [
        "\n",
        "# ====================== Optional ======================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pemFEQB08-em"
      },
      "source": [
        "# Zip folder and anns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMJZr0dmkjDc"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "source_directory = '/content/person_train_copy_paste'\n",
        "annotation_file = '/content/annotations.json'\n",
        "\n",
        "import zipfile\n",
        "\n",
        "zip_filename = \"/content/2_BUN_80%copy_paste_train_doar_cu_persoane_BUN.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for i in range(2, 3):\n",
        "      for foldername, subfolders, filenames in os.walk(f'{source_directory}{i}'):\n",
        "          for filename in filenames:\n",
        "              file_path = os.path.join(foldername, filename)\n",
        "\n",
        "              arcname = os.path.relpath(file_path, '/content/')\n",
        "\n",
        "              zipf.write(file_path, arcname)\n",
        "\n",
        "      zipf.write(f\"/content/annotations_{i}.json\", os.path.basename(f\"/content/annotations_{i}.json\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSBqXEMp9HoH"
      },
      "source": [
        "# Optional - copy to drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_zip = zip_filename\n",
        "destination_path = f'/content/drive/MyDrive/A_new_datasets/ULTIMUL_SET{zip_filename[9:]}'\n",
        "shutil.copy2(source_zip, destination_path)\n"
      ],
      "metadata": {
        "id": "kgapiqcbJIpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fhcfpn1wBCV",
        "outputId": "5fd16d88-d9e0-467b-86e5-1b4b395c8099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "340473 262465 323681 340473\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def count_person_instances(file_path):\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    if \"categories\" not in data:\n",
        "        raise ValueError(\"The JSON file does not contain 'categories'.\")\n",
        "\n",
        "    person_id = None\n",
        "    for category in data[\"categories\"]:\n",
        "        if category[\"name\"] == \"person\":\n",
        "            person_id = category[\"id\"]\n",
        "            break\n",
        "\n",
        "    if person_id is None:\n",
        "        raise ValueError(\" 'person' category wasn't found in the JSON file.\")\n",
        "    count = 0\n",
        "    for annotation in data[\"annotations\"]:\n",
        "        if annotation[\"category_id\"] == person_id:\n",
        "            count += 1\n",
        "\n",
        "    return count\n",
        "\n",
        "print(count_person_instances(\"/content/annotations_1.json\"),\n",
        "  count_person_instances(\"/content/annotations/instances_train2017.json\"),\n",
        "  count_person_instances(\"/content/annotations_2.json\"),\n",
        "  count_person_instances(\"/content/annotations_3.json\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taCJAvEi9oTl"
      },
      "source": [
        "# Restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSieI81z9nR1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}